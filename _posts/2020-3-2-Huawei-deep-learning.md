---
layout: post
title: "Huawei -deep-learning"
date: 2020-3-2
excerpt: "The neural network of deep learning used to realize spot recognition"
tags: [Notes,Deep-learning]
project: ture
##  华为云---深度学习之构建神经网络实现景区识别

####  图像预处理
<br>
 &nbsp;  ○ 输字构造模型的时，入层是非弹性的，素以需要明确自己能够接受多大数据，因此需要同一图像分辨率，也就是总的像素点个数，彩色图向每个像素点对应三个数字RJB，
 <br>
 &nbsp; ○ 随机裁剪图片
 <br>
&nbsp;  &nbsp; § 因为每个图片中目标可能上下左右方位不一样，与实际缩放距离有差距
<br>
&nbsp; ○ 更改颜色空间，可能因为夜晚而与实际有误差
<br>
• 卷积神经网络是用于处理具有类似网格结构的数据的神经网络，例如时间序列和图像数据，卷积是一种数学运算
<br>
• 输入图像-卷积层对图像处理--生成多个feature map--池化层对FM进行缩减，减少计算量，防止过拟合，再次卷积，再次提取特征，再次池化--平坦层，把二维矩阵变成一维向量
<br>
• 卷积层和池化层都是在二维空间进行，在全连接层使用一维数据，需要加入
<br>
• softmax输出层，神经网络中都是数字，但是输出是向量，softmax把数字转换为概率，转换为标识类别的向量，右边的数值加起来等于一，取最大的，类别都是由字符串组成
<br>
• 独热编码，one-hot encoding，1所在的位置是有效的，用响亮准确标示类别
<br>
• 卷积神经网络结构-正则化层-防止过拟合-即学过的事物可以很好地分辨，但遇到新事物就表现的很差
<br>
&nbsp;  ○ 正则化的方法
<br>
&nbsp;  &nbsp; § dropout随机扔掉一些神经元和特征
<br>
&nbsp;  &nbsp; § L1L1正则化 限制模型复杂度
<br>
&nbsp;  &nbsp; § 提前停止训练，模型正在学习特征，但还没到过拟合的程度就停止了学习
<br>
• 输入层（接收图片）---卷积层+正则化层（卷积层可以作为输入层）---池化层+正则化层--平坦层（因为只是简单地二维变一维，所以不需要正则化层）---全连接层+正则化层---输出层
<br>
#### CNN模型构建：
<br>
&nbsp; ○ 创建空模型
<br>
&nbsp; ○ 添加输入层，指定输入大小
<br>
&nbsp; ○ 添加卷积层，制定卷积核大小和数量
<br>
&nbsp; ○ 添加正则化层，指定丢弃神经元比例
<br>
&nbsp; ○ 添加池化层，设置池化参数
<br>
&nbsp; ○ 重复以上步骤，….
<br>
• 设置模型训练参数
<br>
&nbsp; ○ 指定损失函数
<br>
&nbsp; &nbsp; § 用于衡量预测值和实际值的距离
<br>
&nbsp; ○ 指定优化器≈学习方法
<br>
&nbsp; &nbsp; § 优化器决定模型如何改进，使预测值更加接近实际值
<br>
&nbsp; ○ 指定验证集的比例
<br>
&nbsp; &nbsp; § 用于改进模型训练效果
<br>
&nbsp;○ 指定其他训练参数
<br>&nbsp; &nbsp;§ 设置模型训练周期等
<br>• 损失函数的介绍：
<br>&nbsp; ○ 训练模型的目的：让实际值和预测值之间的距离变小
<br>&nbsp; ○ 常用的损失函数
<br>&nbsp; &nbsp;§ 交叉熵 ，复杂的数学公式
<br>&nbsp;&nbsp; § 0-1误差，不考虑距离把心有多远
<br>&nbsp; ○ 实际应用
<br>&nbsp;&nbsp; § 打中靶心就是正确，否则是错的，则使用MSE和0-1误差
<br>• 训练集包括验证集，测试集则是另一部分
<br>&nbsp; ○ 测试集考察模型的泛化能力
<br>####  参数调优介绍：
<br>&nbsp; ○ 增加训练周期
<br>&nbsp; ○ 更改卷积核数量
<br>&nbsp; ○ 更改卷积核大小
<br>&nbsp; ○ 增加卷积层数量
<br>&nbsp; ○ 更改池化层大小
<br>• 模型评估---使模型泛化能力增强


